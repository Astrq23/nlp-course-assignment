{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d456c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Task 1.1: Tạo Tensor ---\n",
      "Tensor từ list:\n",
      " tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "\n",
      "Tensor từ NumPy array:\n",
      " tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "\n",
      "Ones Tensor:\n",
      " tensor([[1, 1],\n",
      "        [1, 1]])\n",
      "\n",
      "Random Tensor:\n",
      " tensor([[0.3060, 0.9406],\n",
      "        [0.3201, 0.8320]])\n",
      "\n",
      "Shape của tensor: torch.Size([2, 2])\n",
      "Datatype của tensor: torch.float32\n",
      "Device lưu trữ tensor: cpu\n",
      "\n",
      "--- Task 1.2: Các phép toán ---\n",
      "Cộng x_data với chính nó:\n",
      " tensor([[2, 4],\n",
      "        [6, 8]])\n",
      "\n",
      "Nhân x_data với 5:\n",
      " tensor([[ 5, 10],\n",
      "        [15, 20]])\n",
      "\n",
      "Nhân ma trận x_data với x_data.T:\n",
      " tensor([[ 5, 11],\n",
      "        [11, 25]])\n",
      "\n",
      "--- Task 1.3: Indexing và Slicing ---\n",
      "Hàng đầu tiên:\n",
      " tensor([1, 2])\n",
      "\n",
      "Cột thứ hai:\n",
      " tensor([2, 4])\n",
      "\n",
      "Giá trị (hàng 2, cột 2): 4\n",
      "\n",
      "--- Task 1.4: Thay đổi hình dạng ---\n",
      "Tensor (4, 4) ban đầu:\n",
      " tensor([[0.4326, 0.0087, 0.0652, 0.2222],\n",
      "        [0.9713, 0.5409, 0.7011, 0.4730],\n",
      "        [0.5349, 0.2061, 0.2358, 0.1998],\n",
      "        [0.5024, 0.5517, 0.2806, 0.2013]])\n",
      "\n",
      "Tensor (16, 1) sau khi view:\n",
      " tensor([[0.4326],\n",
      "        [0.0087],\n",
      "        [0.0652],\n",
      "        [0.2222],\n",
      "        [0.9713],\n",
      "        [0.5409],\n",
      "        [0.7011],\n",
      "        [0.4730],\n",
      "        [0.5349],\n",
      "        [0.2061],\n",
      "        [0.2358],\n",
      "        [0.1998],\n",
      "        [0.5024],\n",
      "        [0.5517],\n",
      "        [0.2806],\n",
      "        [0.2013]])\n",
      "\n",
      "Shape mới: torch.Size([16, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# --- Task 1.1: Tạo Tensor (Như trong đề bài) ---\n",
    "print(\"--- Task 1.1: Tạo Tensor ---\")\n",
    "# Tạo tensor từ list\n",
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "print(f\"Tensor từ list:\\n {x_data}\\n\")\n",
    "\n",
    "# Tạo tensor từ NumPy array\n",
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "print(f\"Tensor từ NumPy array:\\n {x_np}\\n\")\n",
    "\n",
    "# Tạo tensor với các giá trị ngẫu nhiên hoặc hằng số\n",
    "x_ones = torch.ones_like(x_data) # tạo tensor gồm các số 1 có cùng shape với x_data\n",
    "print(f\"Ones Tensor:\\n {x_ones}\\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # tạo tensor ngẫu nhiên\n",
    "print(f\"Random Tensor:\\n {x_rand}\\n\")\n",
    "\n",
    "# In ra shape, dtype, và device của tensor\n",
    "print(f\"Shape của tensor: {x_rand.shape}\")\n",
    "print(f\"Datatype của tensor: {x_rand.dtype}\")\n",
    "print(f\"Device lưu trữ tensor: {x_rand.device}\\n\")\n",
    "\n",
    "\n",
    "# --- Task 1.2: Các phép toán trên Tensor ---\n",
    "print(\"--- Task 1.2: Các phép toán ---\")\n",
    "\n",
    "# 1. Cộng x_data với chính nó\n",
    "sum_tensor = x_data + x_data\n",
    "print(f\"Cộng x_data với chính nó:\\n {sum_tensor}\\n\")\n",
    "\n",
    "# 2. Nhân x_data với 5\n",
    "mul_tensor = x_data * 5\n",
    "print(f\"Nhân x_data với 5:\\n {mul_tensor}\\n\")\n",
    "\n",
    "# 3. Nhân ma trận x_data với x_data.T\n",
    "# x_data.T là ma trận chuyển vị của x_data\n",
    "transpose_tensor = x_data.T\n",
    "matmul_tensor = x_data @ transpose_tensor\n",
    "print(f\"Nhân ma trận x_data với x_data.T:\\n {matmul_tensor}\\n\")\n",
    "\n",
    "\n",
    "# --- Task 1.3: Indexing và Slicing ---\n",
    "print(\"--- Task 1.3: Indexing và Slicing ---\")\n",
    "\n",
    "# 1. Lấy ra hàng đầu tiên\n",
    "first_row = x_data[0] # Hoặc x_data[0, :]\n",
    "print(f\"Hàng đầu tiên:\\n {first_row}\\n\")\n",
    "\n",
    "# 2. Lấy ra cột thứ hai (index 1)\n",
    "second_col = x_data[:, 1]\n",
    "print(f\"Cột thứ hai:\\n {second_col}\\n\")\n",
    "\n",
    "# 3. Lấy ra giá trị ở hàng thứ hai (index 1), cột thứ hai (index 1)\n",
    "element_1_1 = x_data[1, 1]\n",
    "print(f\"Giá trị (hàng 2, cột 2): {element_1_1}\\n\")\n",
    "\n",
    "\n",
    "# --- Task 1.4: Thay đổi hình dạng Tensor ---\n",
    "print(\"--- Task 1.4: Thay đổi hình dạng ---\")\n",
    "\n",
    "# Tạo một tensor có shape (4, 4)\n",
    "tensor_4x4 = torch.rand(4, 4)\n",
    "print(f\"Tensor (4, 4) ban đầu:\\n {tensor_4x4}\\n\")\n",
    "\n",
    "# Sử dụng view để biến nó thành (16, 1)\n",
    "# .view() và .reshape() khá tương đồng, .view() yêu cầu dữ liệu phải liền mạch trong bộ nhớ\n",
    "tensor_16x1 = tensor_4x4.view(16, 1)\n",
    "print(f\"Tensor (16, 1) sau khi view:\\n {tensor_16x1}\\n\")\n",
    "print(f\"Shape mới: {tensor_16x1.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4810eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Task 2.1: Thực hành với autograd ---\n",
      "x: tensor([1.], requires_grad=True)\n",
      "y: tensor([3.], grad_fn=<AddBackward0>)\n",
      "grad_fn của y: <AddBackward0 object at 0x00000197E4BE7B20>\n",
      "z: tensor([27.], grad_fn=<MulBackward0>)\n",
      "Đang gọi z.backward() lần 1...\n",
      "Đạo hàm của z theo x (lần 1): tensor([18.])\n",
      "\n",
      "--- Thử gọi z.backward() lần 2 ---\n",
      "Lỗi xảy ra khi gọi backward() lần 2:\n",
      " Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# --- Task 2.1: Thực hành với autograd ---\n",
    "print(\"--- Task 2.1: Thực hành với autograd ---\")\n",
    "\n",
    "# Tạo một tensor và yêu cầu tính đạo hàm cho nó\n",
    "x = torch.ones(1, requires_grad=True)\n",
    "print(f\"x: {x}\")\n",
    "\n",
    "# Thực hiện một phép toán\n",
    "y = x + 2\n",
    "print(f\"y: {y}\")\n",
    "\n",
    "# y được tạo ra từ một phép toán có x, nên nó cũng có grad_fn\n",
    "print(f\"grad_fn của y: {y.grad_fn}\")\n",
    "\n",
    "# Thực hiện thêm các phép toán\n",
    "z = y * y * 3\n",
    "print(f\"z: {z}\")\n",
    "\n",
    "# Tính đạo hàm của z theo x\n",
    "print(\"Đang gọi z.backward() lần 1...\")\n",
    "z.backward() # tương đương z.backward(torch.tensor(1.))\n",
    "\n",
    "# Đạo hàm được lưu trong thuộc tính .grad\n",
    "# Ta có z = 3 * (x+2)^2 => dz/dx = 6 * (x+2). Với x=1, dz/dx = 18\n",
    "print(f\"Đạo hàm của z theo x (lần 1): {x.grad}\")\n",
    "\n",
    "print(\"\\n--- Thử gọi z.backward() lần 2 ---\")\n",
    "try:\n",
    "    z.backward()\n",
    "except RuntimeError as e:\n",
    "    print(f\"Lỗi xảy ra khi gọi backward() lần 2:\\n {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a189a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Task 3.1: Lớp nn.Linear ---\n",
      "Input shape (Linear): torch.Size([3, 5])\n",
      "Output shape (Linear): torch.Size([3, 2])\n",
      "Output (Linear):\n",
      " tensor([[-0.4182,  0.1468],\n",
      "        [ 0.4234,  0.3472],\n",
      "        [-0.4937,  0.0137]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "--- Task 3.2: Lớp nn.Embedding ---\n",
      "Input shape (Embedding): torch.Size([4])\n",
      "Output shape (Embedding): torch.Size([4, 3])\n",
      "Embeddings:\n",
      " tensor([[ 0.5441,  0.3454,  0.3232],\n",
      "        [ 0.5758, -0.3957, -1.0751],\n",
      "        [ 0.5931,  1.1384,  1.0332],\n",
      "        [-0.2861, -0.6040, -0.7976]], grad_fn=<EmbeddingBackward0>)\n",
      "\n",
      "--- Task 3.3: Kết hợp thành một nn.Module ---\n",
      "Model input shape: torch.Size([1, 4])\n",
      "Model output shape: torch.Size([1, 4, 2])\n",
      "Model output (sample):\n",
      " tensor([[[-0.1394,  0.2447],\n",
      "         [ 0.1221,  0.1820],\n",
      "         [ 0.3325,  0.1082],\n",
      "         [-0.0816,  0.2725]]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# --- Task 3.1: Lớp nn.Linear ---\n",
    "print(\"--- Task 3.1: Lớp nn.Linear ---\")\n",
    "# Khởi tạo một lớp Linear biến đổi từ 5 chiều -> 2 chiều\n",
    "linear_layer = torch.nn.Linear(in_features=5, out_features=2)\n",
    "\n",
    "# Tạo một tensor đầu vào mẫu\n",
    "input_tensor = torch.randn(3, 5) # 3 mẫu, mỗi mẫu 5 chiều\n",
    "\n",
    "# Truyền đầu vào qua lớp linear\n",
    "output = linear_layer(input_tensor)\n",
    "print(f\"Input shape (Linear): {input_tensor.shape}\")\n",
    "print(f\"Output shape (Linear): {output.shape}\")\n",
    "print(f\"Output (Linear):\\n {output}\\n\")\n",
    "\n",
    "\n",
    "# --- Task 3.2: Lớp nn.Embedding ---\n",
    "print(\"--- Task 3.2: Lớp nn.Embedding ---\")\n",
    "# Khởi tạo lớp Embedding cho một từ điển 10 từ, mỗi từ biểu diễn bằng vector 3 chiều\n",
    "embedding_layer = torch.nn.Embedding(num_embeddings=10, embedding_dim=3)\n",
    "\n",
    "# Tạo một tensor đầu vào chứa các chỉ số của từ (ví dụ: một câu)\n",
    "# Các chỉ số phải nhỏ hơn 10\n",
    "input_indices = torch.LongTensor([1, 5, 0, 8])\n",
    "\n",
    "# Lấy ra các vector embedding tương ứng\n",
    "embeddings = embedding_layer(input_indices)\n",
    "print(f\"Input shape (Embedding): {input_indices.shape}\")\n",
    "print(f\"Output shape (Embedding): {embeddings.shape}\")\n",
    "print(f\"Embeddings:\\n {embeddings}\\n\")\n",
    "\n",
    "\n",
    "# --- Task 3.3: Kết hợp thành một nn.Module ---\n",
    "print(\"--- Task 3.3: Kết hợp thành một nn.Module ---\")\n",
    "\n",
    "class MyFirstModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super(MyFirstModel, self).__init__()\n",
    "        # Định nghĩa các lớp (layer) bạn sẽ dùng\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear = nn.Linear(embedding_dim, hidden_dim)\n",
    "        self.activation = nn.ReLU() # Hàm kích hoạt\n",
    "        self.output_layer = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, indices):\n",
    "        # Định nghĩa luồng dữ liệu đi qua các lớp\n",
    "        \n",
    "        # 1. Lấy embedding\n",
    "        # Input indices shape: (batch_size, seq_len)\n",
    "        # Output embeds shape: (batch_size, seq_len, embedding_dim)\n",
    "        embeds = self.embedding(indices)\n",
    "        \n",
    "        # 2. Truyền qua lớp linear và hàm kích hoạt\n",
    "        # Output hidden shape: (batch_size, seq_len, hidden_dim)\n",
    "        hidden = self.activation(self.linear(embeds))\n",
    "        \n",
    "        # 3. Truyền qua lớp output\n",
    "        # Output output shape: (batch_size, seq_len, output_dim)\n",
    "        output = self.output_layer(hidden)\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Khởi tạo và kiểm tra mô hình\n",
    "model = MyFirstModel(vocab_size=100, embedding_dim=16, hidden_dim=8, output_dim=2)\n",
    "\n",
    "# Input: 1 batch, 1 câu gồm 4 từ\n",
    "input_data = torch.LongTensor([[1, 2, 5, 9]]) \n",
    "print(f\"Model input shape: {input_data.shape}\")\n",
    "\n",
    "# Chạy mô hình\n",
    "output_data = model(input_data)\n",
    "\n",
    "print(f\"Model output shape: {output_data.shape}\")\n",
    "print(f\"Model output (sample):\\n {output_data}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
